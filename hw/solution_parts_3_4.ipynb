{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT__Ni40Jk8q"
   },
   "source": [
    "## Выполнили: Жерноклеев Дмитрий Дамирович, Индык Илья Андреевич, Реентович Александр Анатольевич\n",
    "\n",
    "# Домашнее задание\n",
    "## Harry Potter and the Action Prediction Challenge from Natural Language\n",
    "\n",
    "*deadline*: 14 ноября 2022, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом Harry Potter and the Action Prediction Challenge. Корпус собран из фанфиков о Гарри Поттере и состоит из двух частей: 1) сырые тексты, 2) фрагменты текстов, описывающих ситуацию, в которой произнесено заклинание.\n",
    "\n",
    "Корпус описан в статье: https://arxiv.org/pdf/1905.11037.pdf\n",
    "\n",
    "David Vilares and Carlos Gómez-Rodríguez. Harry Potter and the Action Prediction Challenge from Natural Language. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics. To appear.\n",
    "\n",
    "Код для сбора корпуса находится в репозитории: https://github.com/aghie/hpac . Корпус можно скачать по инструкции из этого репозитория, но для экономии времени авторы задания уже скачали и подготовили данные к работе. \n",
    "\n",
    "Ссылки на собранный корпус: \n",
    "* Сырые тексты:  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip?dl=0\n",
    "* Токенизированные тексты в нижнем регистре: https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip?dl=0\n",
    "* train-test-dev: https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip?dl=0\n",
    "\n",
    "Части 1, 2 задания должны быть выполнены на полных текстах (сырых или предобработанных -- на ваше усмотрение), Часть 3 – на разбиение на тестовое, отладочное и обучающее множества. Тестовое множество должно быть использовано исключительно для тестирования моделей, обучающее и отладочное – для выбора модели и параметров. \n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 3-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "3. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов.\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия. \n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)\n",
    "\n",
    "## Часть 2. [2 балла] Модели представления слов \n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io).\n",
    "\n",
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?\n",
    "\n",
    "Используйте фрагменты из множества train для обучения, из множества dev для отладки, из множества test – для тестирования и получения итоговых результатов. \n",
    "\n",
    "1. [1 балл] Используйте fastText в качестве baseline-классификатора.\n",
    "2. [2 балла] Используйте сверточные  или реккурентные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling. \n",
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры).\n",
    "\n",
    "[бонус] Используйте результат max pooling'а как эмбеддинг входного текста. Визуализируйте эмбеддинги 500-1000 предложений из обучающего множества и изучите свойства получившегося пространства.\n",
    "\n",
    "[бонус] Используйте ваш любимый классификатор и любые (честные) способы повышения качества классификации и получите macro $F_1$ больше 0.5.\n",
    "\n",
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Читали ли вы сами Гарри Поттера или фанфики о нем и помогло ли вам знание предметной области в выполнении домашнего задания?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnnoTWoBJk8x"
   },
   "source": [
    "### Данные\n",
    "Сырые тексты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIvMsjBjJk8y",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "461da31a-062c-4164-932a-914467e7300c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  hpac_splits.zip\n",
      "   creating: hpac_corpus/\n",
      "  inflating: hpac_corpus/hpac_training_128.tsv  \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/hpac_corpus/\n",
      "  inflating: __MACOSX/hpac_corpus/._hpac_training_128.tsv  \n",
      "  inflating: hpac_corpus/hpac_dev_128.tsv  \n",
      "  inflating: __MACOSX/hpac_corpus/._hpac_dev_128.tsv  \n",
      "  inflating: hpac_corpus/hpac_test_128.tsv  \n",
      "  inflating: __MACOSX/hpac_corpus/._hpac_test_128.tsv  \n",
      "  inflating: __MACOSX/._hpac_corpus  \n"
     ]
    }
   ],
   "source": [
    "!unzip hpac_splits.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNme2YzIys1P",
    "outputId": "ce8f1ccf-81d9-4276-c10b-c63094786d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  w2v_model.zip\n",
      "  inflating: hpac_w2v.model          \n",
      "  inflating: hpac_w2v.model.syn1neg.npy  \n",
      "  inflating: hpac_w2v.model.wv.vectors.npy  \n"
     ]
    }
   ],
   "source": [
    "!unzip w2v_model.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuslguwiJk8z"
   },
   "source": [
    "train, test, dev файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US3b_A_B0cfw",
    "outputId": "3c836e5a-5321-49a7-8371-5bc6a6ca400c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gensim==4.2.0 in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==4.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFci4r9yJ9d4"
   },
   "source": [
    "Выпоним предобрабоку данных и уберем те сэмплы, для которых в нашей word2vec модели нет эмбеддингов (тескт состоит из стоп слов или заклинаний; очевидно, одна фраза из диалога попала в текст для обучения, а следующая - в метку класса данного текста)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F1SGM7RJJk80"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('hpac_corpus/hpac_training_128.tsv', sep = '\\t', header = None)\n",
    "df_test = pd.read_csv('hpac_corpus/hpac_test_128.tsv', sep = '\\t', header = None)\n",
    "df_dev = pd.read_csv('hpac_corpus/hpac_dev_128.tsv', sep = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IaFejFJ3_MTr"
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "df.iloc[:, 2] = df.iloc[:, 2].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "df.iloc[:, 1] = df.iloc[:, 1].apply(lambda x: '__label__' + x)\n",
    "\n",
    "df_test.iloc[:, 2] = df_test.iloc[:, 2].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "df_test.iloc[:, 1] = df_test.iloc[:, 1].apply(lambda x: '__label__' + x)\n",
    "\n",
    "df_dev.iloc[:, 2] = df_dev.iloc[:, 2].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "df_dev.iloc[:, 1] = df_dev.iloc[:, 1].apply(lambda x: '__label__' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "288JfWUEPhoO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "class Text2VecTransformer:\n",
    "    def __init__(self, model_dir='./'):\n",
    "        model = Word2Vec.load(model_dir + \"hpac_w2v.model\")\n",
    "        self.model = model\n",
    "        \n",
    "    def transform(self, text: str):\n",
    "        vecs = []\n",
    "        for word in text.split():\n",
    "            try:\n",
    "                word_embedding = self.model.wv[word]\n",
    "                vecs.append(word_embedding)\n",
    "            except KeyError:  # если слова нет в словаре w2v, то пропускаем его\n",
    "                continue\n",
    "                \n",
    "        vecs = np.array(vecs)\n",
    "        return self.aggregation(vecs)\n",
    "        \n",
    "    def aggregation(self, vecs: np.array):\n",
    "        return np.mean(vecs, axis=0)\n",
    "#         return np.max(vecs, axis=0)  # max-pool ?\n",
    "    \n",
    "    def text_summary(self, text: str):\n",
    "        \"\"\"Для проверки на здравый смысл и поиска лучшей функции агрегации\"\"\"\n",
    "        return model.wv.similar_by_vector(self.transform(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_IpjTElCNIt",
    "outputId": "d33f1f0b-dc04-4127-efa9-85dd0c6f4538"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Remove samples with no embeddings\n",
    "vectorizer = Text2VecTransformer()\n",
    "mask_train = df.iloc[:, 2].apply(lambda x: vectorizer.transform(x).sum())\n",
    "mask_test = df_test.iloc[:, 2].apply(lambda x: vectorizer.transform(x).sum())\n",
    "mask_dev = df_dev.iloc[:, 2].apply(lambda x: vectorizer.transform(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "viiU8BK-gkZP"
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[np.isnan(mask_train)].index).reset_index(drop=True)\n",
    "df_test = df_test.drop(df_test[np.isnan(mask_test)].index).reset_index(drop=True)\n",
    "df_dev = df_dev.drop(df_dev[np.isnan(mask_dev)].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz8yh0ccgmrY"
   },
   "source": [
    "# Часть 3\n",
    "## 1. Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_Z-4FNbVGMx",
    "outputId": "5dc226cf-b064-4443-ce55-24dafdb82311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-17 14:35:18--  https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/facebookresearch/fastText/zip/refs/tags/v0.9.2 [following]\n",
      "--2022-11-17 14:35:18--  https://codeload.github.com/facebookresearch/fastText/zip/refs/tags/v0.9.2\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.121.9\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.121.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘v0.9.2.zip’\n",
      "\n",
      "v0.9.2.zip              [  <=>               ]   4.17M  11.3MB/s    in 0.4s    \n",
      "\n",
      "2022-11-17 14:35:19 (11.3 MB/s) - ‘v0.9.2.zip’ saved [4369852]\n",
      "\n",
      "Archive:  v0.9.2.zip\n",
      "5b5943c118b0ec5fb9cd8d20587de2b2d3966dfe\n",
      "   creating: fastText-0.9.2/\n",
      "   creating: fastText-0.9.2/.circleci/\n",
      "  inflating: fastText-0.9.2/.circleci/cmake_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/config.yml  \n",
      "  inflating: fastText-0.9.2/.circleci/gcc_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/pip_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/pull_data.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/python_test.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/run_locally.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/setup_circleimg.sh  \n",
      "  inflating: fastText-0.9.2/.circleci/setup_debian.sh  \n",
      "  inflating: fastText-0.9.2/.gitignore  \n",
      "  inflating: fastText-0.9.2/CMakeLists.txt  \n",
      "  inflating: fastText-0.9.2/CODE_OF_CONDUCT.md  \n",
      "  inflating: fastText-0.9.2/CONTRIBUTING.md  \n",
      "  inflating: fastText-0.9.2/LICENSE  \n",
      "  inflating: fastText-0.9.2/MANIFEST.in  \n",
      "  inflating: fastText-0.9.2/Makefile  \n",
      "  inflating: fastText-0.9.2/README.md  \n",
      "   creating: fastText-0.9.2/alignment/\n",
      "  inflating: fastText-0.9.2/alignment/README.md  \n",
      "  inflating: fastText-0.9.2/alignment/align.py  \n",
      "  inflating: fastText-0.9.2/alignment/eval.py  \n",
      "  inflating: fastText-0.9.2/alignment/example.sh  \n",
      "  inflating: fastText-0.9.2/alignment/unsup_align.py  \n",
      "  inflating: fastText-0.9.2/alignment/unsup_multialign.py  \n",
      "  inflating: fastText-0.9.2/alignment/utils.py  \n",
      "  inflating: fastText-0.9.2/classification-example.sh  \n",
      "  inflating: fastText-0.9.2/classification-results.sh  \n",
      "   creating: fastText-0.9.2/crawl/\n",
      "  inflating: fastText-0.9.2/crawl/README.md  \n",
      "  inflating: fastText-0.9.2/crawl/dedup.cc  \n",
      "  inflating: fastText-0.9.2/crawl/download_crawl.sh  \n",
      "  inflating: fastText-0.9.2/crawl/filter_dedup.sh  \n",
      "  inflating: fastText-0.9.2/crawl/filter_utf8.cc  \n",
      "  inflating: fastText-0.9.2/crawl/process_wet_file.sh  \n",
      "   creating: fastText-0.9.2/docs/\n",
      "  inflating: fastText-0.9.2/docs/aligned-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/api.md  \n",
      "  inflating: fastText-0.9.2/docs/autotune.md  \n",
      "  inflating: fastText-0.9.2/docs/cheatsheet.md  \n",
      "  inflating: fastText-0.9.2/docs/crawl-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/dataset.md  \n",
      "  inflating: fastText-0.9.2/docs/english-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/faqs.md  \n",
      "  inflating: fastText-0.9.2/docs/language-identification.md  \n",
      "  inflating: fastText-0.9.2/docs/options.md  \n",
      "  inflating: fastText-0.9.2/docs/pretrained-vectors.md  \n",
      "  inflating: fastText-0.9.2/docs/python-module.md  \n",
      "  inflating: fastText-0.9.2/docs/references.md  \n",
      "  inflating: fastText-0.9.2/docs/supervised-models.md  \n",
      "  inflating: fastText-0.9.2/docs/supervised-tutorial.md  \n",
      "  inflating: fastText-0.9.2/docs/support.md  \n",
      "  inflating: fastText-0.9.2/docs/unsupervised-tutorials.md  \n",
      "  inflating: fastText-0.9.2/docs/webassembly-module.md  \n",
      "  inflating: fastText-0.9.2/download_model.py  \n",
      "  inflating: fastText-0.9.2/eval.py  \n",
      "  inflating: fastText-0.9.2/fasttext.pc.in  \n",
      "  inflating: fastText-0.9.2/get-wikimedia.sh  \n",
      "   creating: fastText-0.9.2/python/\n",
      "  inflating: fastText-0.9.2/python/README.md  \n",
      "  inflating: fastText-0.9.2/python/README.rst  \n",
      "   creating: fastText-0.9.2/python/benchmarks/\n",
      "  inflating: fastText-0.9.2/python/benchmarks/README.rst  \n",
      "  inflating: fastText-0.9.2/python/benchmarks/get_word_vector.py  \n",
      "   creating: fastText-0.9.2/python/doc/\n",
      "   creating: fastText-0.9.2/python/doc/examples/\n",
      "  inflating: fastText-0.9.2/python/doc/examples/FastTextEmbeddingBag.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/bin_to_vec.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/compute_accuracy.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/get_vocab.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/train_supervised.py  \n",
      "  inflating: fastText-0.9.2/python/doc/examples/train_unsupervised.py  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/\n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/FastText.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/__init__.py  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/fasttext_pybind.cc  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/tests/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/__init__.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_configurations.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_script.py  \n",
      "   creating: fastText-0.9.2/python/fasttext_module/fasttext/util/\n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/__init__.py  \n",
      "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/util.py  \n",
      "  inflating: fastText-0.9.2/quantization-example.sh  \n",
      "  inflating: fastText-0.9.2/reduce_model.py  \n",
      "  inflating: fastText-0.9.2/runtests.py  \n",
      "   creating: fastText-0.9.2/scripts/\n",
      "   creating: fastText-0.9.2/scripts/kbcompletion/\n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/README.md  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/data.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/eval.cpp  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k237.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/svo.sh  \n",
      "  inflating: fastText-0.9.2/scripts/kbcompletion/wn18.sh  \n",
      "   creating: fastText-0.9.2/scripts/quantization/\n",
      "  inflating: fastText-0.9.2/scripts/quantization/quantization-results.sh  \n",
      " extracting: fastText-0.9.2/setup.cfg  \n",
      "  inflating: fastText-0.9.2/setup.py  \n",
      "   creating: fastText-0.9.2/src/\n",
      "  inflating: fastText-0.9.2/src/args.cc  \n",
      "  inflating: fastText-0.9.2/src/args.h  \n",
      "  inflating: fastText-0.9.2/src/autotune.cc  \n",
      "  inflating: fastText-0.9.2/src/autotune.h  \n",
      "  inflating: fastText-0.9.2/src/densematrix.cc  \n",
      "  inflating: fastText-0.9.2/src/densematrix.h  \n",
      "  inflating: fastText-0.9.2/src/dictionary.cc  \n",
      "  inflating: fastText-0.9.2/src/dictionary.h  \n",
      "  inflating: fastText-0.9.2/src/fasttext.cc  \n",
      "  inflating: fastText-0.9.2/src/fasttext.h  \n",
      "  inflating: fastText-0.9.2/src/loss.cc  \n",
      "  inflating: fastText-0.9.2/src/loss.h  \n",
      "  inflating: fastText-0.9.2/src/main.cc  \n",
      "  inflating: fastText-0.9.2/src/matrix.cc  \n",
      "  inflating: fastText-0.9.2/src/matrix.h  \n",
      "  inflating: fastText-0.9.2/src/meter.cc  \n",
      "  inflating: fastText-0.9.2/src/meter.h  \n",
      "  inflating: fastText-0.9.2/src/model.cc  \n",
      "  inflating: fastText-0.9.2/src/model.h  \n",
      "  inflating: fastText-0.9.2/src/productquantizer.cc  \n",
      "  inflating: fastText-0.9.2/src/productquantizer.h  \n",
      "  inflating: fastText-0.9.2/src/quantmatrix.cc  \n",
      "  inflating: fastText-0.9.2/src/quantmatrix.h  \n",
      "  inflating: fastText-0.9.2/src/real.h  \n",
      "  inflating: fastText-0.9.2/src/utils.cc  \n",
      "  inflating: fastText-0.9.2/src/utils.h  \n",
      "  inflating: fastText-0.9.2/src/vector.cc  \n",
      "  inflating: fastText-0.9.2/src/vector.h  \n",
      "   creating: fastText-0.9.2/tests/\n",
      "  inflating: fastText-0.9.2/tests/fetch_test_data.sh  \n",
      "   creating: fastText-0.9.2/webassembly/\n",
      "  inflating: fastText-0.9.2/webassembly/README.md  \n",
      "   creating: fastText-0.9.2/webassembly/doc/\n",
      "   creating: fastText-0.9.2/webassembly/doc/examples/\n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/misc.html  \n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/predict.html  \n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/train_supervised.html  \n",
      "  inflating: fastText-0.9.2/webassembly/doc/examples/train_unsupervised.html  \n",
      "  inflating: fastText-0.9.2/webassembly/fasttext.js  \n",
      "  inflating: fastText-0.9.2/webassembly/fasttext_wasm.cc  \n",
      "   creating: fastText-0.9.2/website/\n",
      "  inflating: fastText-0.9.2/website/README.md  \n",
      "   creating: fastText-0.9.2/website/blog/\n",
      "  inflating: fastText-0.9.2/website/blog/2016-08-18-blog-post.md  \n",
      "  inflating: fastText-0.9.2/website/blog/2017-05-02-blog-post.md  \n",
      "  inflating: fastText-0.9.2/website/blog/2017-10-02-blog-post.md  \n",
      "  inflating: fastText-0.9.2/website/blog/2019-06-25-blog-post.md  \n",
      "   creating: fastText-0.9.2/website/core/\n",
      "  inflating: fastText-0.9.2/website/core/Footer.js  \n",
      "  inflating: fastText-0.9.2/website/package.json  \n",
      "   creating: fastText-0.9.2/website/pages/\n",
      "   creating: fastText-0.9.2/website/pages/en/\n",
      "  inflating: fastText-0.9.2/website/pages/en/index.js  \n",
      "  inflating: fastText-0.9.2/website/sidebars.json  \n",
      "  inflating: fastText-0.9.2/website/siteConfig.js  \n",
      "   creating: fastText-0.9.2/website/static/\n",
      "   creating: fastText-0.9.2/website/static/docs/\n",
      "   creating: fastText-0.9.2/website/static/docs/en/\n",
      "   creating: fastText-0.9.2/website/static/docs/en/html/\n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/.classfasttext_1_1QMatrix-members.html.i4eKqy  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated_dup.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h_source.html  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/bc_s.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/bdwn.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classes.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/closed.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/doc.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/doxygen.css  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/doxygen.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/dynsections.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/favicon.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/files.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/files.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/folderclosed.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/folderopen.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_0x7e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_dup.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_func.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_g.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_i.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_k.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_l.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_m.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_n.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_o.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_p.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_q.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_r.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_s.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_t.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_u.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_v.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_vars.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_w.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_z.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/globals.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_defs.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_func.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/index.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/jquery.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/menu.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/menudata.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext_1_1utils.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_enum.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_func.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_type.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/nav_f.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_g.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_h.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.css  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreedata.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/open.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/resize.js  \n",
      "   creating: fastText-0.9.2/website/static/docs/en/html/search/\n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/.files_7.html.StRRNc  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/.variables_a.html.1MGQ27  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/close.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/mag_sel.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/nomatches.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.css  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_l.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search_m.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_r.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/searchdata.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/splitbar.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry-members.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.js  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/sync_off.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/sync_on.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_a.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_b.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_h.png  \n",
      " extracting: fastText-0.9.2/website/static/docs/en/html/tab_s.png  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/tabs.css  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.html  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.js  \n",
      "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h_source.html  \n",
      "  inflating: fastText-0.9.2/website/static/fasttext.css  \n",
      "   creating: fastText-0.9.2/website/static/img/\n",
      "   creating: fastText-0.9.2/website/static/img/authors/\n",
      "  inflating: fastText-0.9.2/website/static/img/authors/armand_joulin.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/christian_puhrsch.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/edouard_grave.jpeg  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/piotr_bojanowski.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/authors/tomas_mikolov.jpg  \n",
      "   creating: fastText-0.9.2/website/static/img/blog/\n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img1.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img2.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img1.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img2.jpg  \n",
      "  inflating: fastText-0.9.2/website/static/img/blog/2017-10-02-blog-post-img1.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/cbo_vs_skipgram.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-api.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-bg-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-square.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-faq.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-tutorial.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-white-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-color-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-white-web.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/logo-color.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/model-black.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/model-blue.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/model-red.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/ogimage.png  \n",
      "  inflating: fastText-0.9.2/website/static/img/oss_logo.png  \n",
      "  inflating: fastText-0.9.2/website/static/tabber.js  \n",
      "  inflating: fastText-0.9.2/wikifil.pl  \n",
      "  inflating: fastText-0.9.2/word-vector-example.sh  \n",
      "/content/fastText-0.9.2/fastText-0.9.2\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
    "!unzip v0.9.2.zip\n",
    "%cd fastText-0.9.2\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02TU8nmLdOBo",
    "outputId": "34b6c309-29e5-405a-d4cd-c27dbdb6ac4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 6.3 MB/s \n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3159017 sha256=4db4a411d9449c266de9740304f76af3b450479155a7965afbd3720f5ed74356\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txBIrOG3y_Re"
   },
   "source": [
    "Основа для кода ниже взята из: https://towardsdatascience.com/fasttext-for-text-classification-a4b38cbff27c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZejYBBwY8XX",
    "outputId": "55e4a050-f572-44c9-cbba-76b6f0c2e794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 score equals 0.1974713242961418\n"
     ]
    }
   ],
   "source": [
    "# Saving the CSV file as a text file to train/test the classifier\n",
    "train_sample = df.loc[:, [1, 2]]\n",
    "train_sample.to_csv('train.txt', index = False, sep = ' ')\n",
    "\n",
    "\n",
    "import fasttext\n",
    "# Training the fastText classifier\n",
    "model = fasttext.train_supervised('train.txt', wordNgrams = 2)\n",
    "\n",
    "test_sample = df_test.loc[:, [1, 2]]\n",
    "test_sample.to_csv('test1.txt', index = False, sep = ' ')\n",
    "# Evaluating performance on the entire test file\n",
    "n, pr, rec = model.test('test1.txt') \n",
    "print('Macro F1 score equals', 2 * (pr * rec) / (pr + rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7sl9apzBgoY"
   },
   "source": [
    "Таким образом, в качестве бенчмарка имеем F1 в размере 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI2dpPHIfm1O"
   },
   "source": [
    "## 2. Самодельная нейросеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qosPIyhNgICK"
   },
   "source": [
    "Нижеследующий код основан на https://coderzcolumn.com/tutorials/artificial-intelligence/pytorch-simple-guide-to-text-classification#2, https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXbArQSzFPGP",
    "outputId": "07b89c13-2fdf-454c-c08d-1af97edb430f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchtext==0.10.1 in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (2.23.0)\n",
      "Requirement already satisfied: torch==1.9.1 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (1.9.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.1) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1->torchtext==0.10.1) (4.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.1) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z9ajYLRHtLN"
   },
   "source": [
    "Загрузим пакеты и предобработаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2Tll6ZfQgfNn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qmWK5cNGQlTq"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "UbjFbYztLN77"
   },
   "outputs": [],
   "source": [
    "train_sample = df.loc[:, [1, 2]]\n",
    "test_sample = df_test.loc[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "UiNxKKcOVVZu"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(np.array(train_sample.loc[:, 1]).reshape(-1, 1))\n",
    "train_sample[1] = enc.transform(np.array(train_sample.loc[:, 1]).reshape(-1, 1))\n",
    "test_sample[1] = enc.transform(np.array(test_sample.loc[:, 1]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "gR9pJaeMWO7s"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    " \n",
    "  def __init__(self, train = True):\n",
    "    if train:\n",
    "      x=train_sample[2].values\n",
    "      y=train_sample[1].values\n",
    "    else:\n",
    "      x=test_sample[2].values\n",
    "      y=test_sample[1].values\n",
    " \n",
    "    self.x_train=x\n",
    "    self.y_train=torch.tensor(y).type(torch.LongTensor)\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.y_train)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_train[idx],self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "WGgA60YEZaGh"
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = MyDataset(), MyDataset(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlmhOtmtFOE5"
   },
   "source": [
    "Сделаем векторизацию батча при помощи Word2Vec эмбеддингов (каждый текст представим в виде среднего эмбеддингов входящих в него слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lvfPV4pTE7Wh"
   },
   "outputs": [],
   "source": [
    "class Text2VecTransformer:\n",
    "    def __init__(self, model_dir='./'):\n",
    "        model = Word2Vec.load(model_dir + \"hpac_w2v.model\")\n",
    "        self.model = model\n",
    "        \n",
    "    def transform(self, text: str):\n",
    "        vecs = []\n",
    "        for word in text.split():\n",
    "            try:\n",
    "                word_embedding = self.model.wv[word]\n",
    "                vecs.append(word_embedding)\n",
    "            except KeyError:  # если слова нет в словаре w2v, то пропускаем его\n",
    "                continue\n",
    "                \n",
    "        vecs = np.array(vecs)\n",
    "        return self.aggregation(vecs)\n",
    "        \n",
    "    def aggregation(self, vecs: np.array):\n",
    "        return np.mean(vecs, axis=0)\n",
    "#         return np.max(vecs, axis=0)  # max-pool ?\n",
    "    \n",
    "    def text_summary(self, text: str):\n",
    "        \"\"\"Для проверки на здравый смысл и поиска лучшей функции агрегации\"\"\"\n",
    "        return model.wv.similar_by_vector(self.transform(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cAztKT3EEL37"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "vectorizer = Text2VecTransformer()\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    X, Y = list(zip(*batch))\n",
    "    X_vect = np.array([vectorizer.transform(x) for x in X])\n",
    "    return torch.tensor(X_vect, dtype=torch.float32), torch.tensor(Y)\n",
    "\n",
    "#train_dataset, test_dataset  = torchtext.datasets.AG_NEWS()\n",
    "#train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, collate_fn=vectorize_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=256, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nibyIl1GFsUe"
   },
   "source": [
    "Напишем классификатор, представляющий собой нейросеть, где сначала вход поступает в LSTM слой, за которым идут два линейных слоя. За основу взят код отсюда: https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ZPRim85rU-R2"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, dimension=128):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        #self.embedding = nn.Embedding(len(text_field.vocab), 300)\n",
    "        self.dimension = dimension\n",
    "        self.lstm = nn.LSTM(input_size=250,\n",
    "                            hidden_size=dimension,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False).to(device)\n",
    "        self.drop = nn.Dropout(p=0.05).to(device)\n",
    "\n",
    "        self.fc1 = nn.Linear(128, 300).to(device)\n",
    "        self.fc2 = nn.Linear(300, len(np.unique(train_sample[1]))).to(device)\n",
    "        self.relu = nn.ReLU().to(device)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        X_batch =  X_batch.reshape(-1,1, 250).to(device)\n",
    "        #packed_input = pack_padded_sequence(fc1_out, text_len, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, _ = self.lstm(X_batch)\n",
    "        lstm_out = self.drop(lstm_out[:,-1])\n",
    "        fc1_out = self.fc1(lstm_out)\n",
    "        fc1_out = self.relu(fc1_out)\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        return fc2_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfemymNimO3-"
   },
   "source": [
    "Попробуем классификатор CNN отсюда: https://towardsdatascience.com/text-classification-with-cnns-in-pytorch-1113df31e79f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "bT8tF9xwmUaZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class CNN(nn.ModuleList):\n",
    "\n",
    "    def __init__(self):\n",
    "      super(CNN, self).__init__()\n",
    "\n",
    "      # Parameters regarding text preprocessing\n",
    "      self.seq_len = 250\n",
    "      #self.num_words = params.num_words\n",
    "      #self.embedding_size = params.embedding_size\n",
    "      \n",
    "      # Dropout definition\n",
    "      self.dropout = nn.Dropout(0.25)\n",
    "      \n",
    "      # CNN parameters definition\n",
    "      # Kernel sizes\n",
    "      self.kernel_1 = 2\n",
    "      self.kernel_2 = 3\n",
    "      self.kernel_3 = 4\n",
    "      self.kernel_4 = 5\n",
    "      \n",
    "      # Output size for each convolution\n",
    "      self.out_size = 1\n",
    "      # Number of strides for each convolution\n",
    "      self.stride = 2\n",
    "      \n",
    "      # Embedding layer definition\n",
    "      #self.embedding = nn.Embedding(self.num_words + 1, self.embedding_size, padding_idx=0)\n",
    "      \n",
    "      # Convolution layers definition\n",
    "      self.conv_1 = nn.Conv1d(1, self.out_size, self.kernel_1, self.stride).to(device)\n",
    "      self.conv_2 = nn.Conv1d(1, self.out_size, self.kernel_2, self.stride).to(device)\n",
    "      self.conv_3 = nn.Conv1d(1, self.out_size, self.kernel_3, self.stride).to(device)\n",
    "      self.conv_4 = nn.Conv1d(1, self.out_size, self.kernel_4, self.stride).to(device)\n",
    "      \n",
    "      # Max pooling layers definition\n",
    "      self.pool_1 = nn.MaxPool1d(self.kernel_1, self.stride).to(device)\n",
    "      self.pool_2 = nn.MaxPool1d(self.kernel_2, self.stride).to(device)\n",
    "      self.pool_3 = nn.MaxPool1d(self.kernel_3, self.stride).to(device)\n",
    "      self.pool_4 = nn.MaxPool1d(self.kernel_4, self.stride).to(device)\n",
    "      \n",
    "      # Fully connected layer definition\n",
    "      self.fc = nn.Linear(244, len(np.unique(train_sample[1]))).to(device)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "\n",
    "      # Sequence of tokes is filterd through an embedding layer\n",
    "      x = torch.reshape(X_batch, (-1, 1, self.seq_len)).to(device)\n",
    "      \n",
    "      # Convolution layer 1 is applied\n",
    "      x1 = self.conv_1(x)\n",
    "      x1 = torch.relu(x1)\n",
    "      x1 = self.pool_1(x1)\n",
    "      \n",
    "      # Convolution layer 2 is applied\n",
    "      x2 = self.conv_2(x)\n",
    "      x2 = torch.relu((x2))\n",
    "      x2 = self.pool_2(x2)\n",
    "   \n",
    "      # Convolution layer 3 is applied\n",
    "      x3 = self.conv_3(x)\n",
    "      x3 = torch.relu(x3)\n",
    "      x3 = self.pool_3(x3)\n",
    "      \n",
    "      # Convolution layer 4 is applied\n",
    "      x4 = self.conv_4(x)\n",
    "      x4 = torch.relu(x4)\n",
    "      x4 = self.pool_4(x4)\n",
    "      \n",
    "      # The output of each convolutional layer is concatenated into a unique vector\n",
    "      union = torch.cat((x1, x2, x3, x4), 2)\n",
    "      union = union.reshape(union.size(0), -1)\n",
    "\n",
    "      # The \"flattened\" vector is passed through a fully connected layer\n",
    "      out = self.fc(union)\n",
    "      # Dropout is applied\t\t\n",
    "      #out = self.dropout(out)\n",
    "      # Activation function is applied\n",
    "      #out = torch.sigmoid(out)\n",
    "      \n",
    "      return out.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep3jeqOxF0gk"
   },
   "source": [
    "Запрограммируем процесс обучения и тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "4mG36cVBwSdw"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import gc\n",
    "\n",
    "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds, losses = [],[],[]\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            Y = Y.to(device)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        print(\"Valid Macro F1  : {:.3f}\".format(f1_score(Y_shuffled.detach().cpu(), Y_preds.detach().cpu(), average='macro')))\n",
    "\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for X, Y in tqdm(train_loader):\n",
    "            Y_preds = model(X)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            loss = loss_fn(Y_preds, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        CalcValLossAndAccuracy(model, loss_fn, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx9tLw4KxEtL"
   },
   "source": [
    "Обучим LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25X1Z57qwW04",
    "outputId": "bb59ea06-a7cf-43f0-cdf0-e56ffe89748e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:19<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.200\n",
      "Valid Loss : 2.954\n",
      "Valid Macro F1  : 0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:19<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.879\n",
      "Valid Loss : 2.836\n",
      "Valid Macro F1  : 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:22<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.789\n",
      "Valid Loss : 2.781\n",
      "Valid Macro F1  : 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:19<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.736\n",
      "Valid Loss : 2.751\n",
      "Valid Macro F1  : 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:19<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.696\n",
      "Valid Loss : 2.737\n",
      "Valid Macro F1  : 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:21<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.663\n",
      "Valid Loss : 2.728\n",
      "Valid Macro F1  : 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:19<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.634\n",
      "Valid Loss : 2.716\n",
      "Valid Macro F1  : 0.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:19<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.608\n",
      "Valid Loss : 2.715\n",
      "Valid Macro F1  : 0.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:23<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.582\n",
      "Valid Loss : 2.711\n",
      "Valid Macro F1  : 0.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:19<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.558\n",
      "Valid Loss : 2.708\n",
      "Valid Macro F1  : 0.089\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#text_classifier = MLP()\n",
    "text_classifier = LSTM()\n",
    "optimizer = Adam(text_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(text_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fue5WkhfxHAo"
   },
   "source": [
    "Обучим CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYnzgoCAswcV",
    "outputId": "e5c99ee4-2d7e-4cfe-d603-85348f381cd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:24<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.453\n",
      "Valid Loss : 3.249\n",
      "Valid Macro F1  : 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:24<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.151\n",
      "Valid Loss : 3.097\n",
      "Valid Macro F1  : 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.043\n",
      "Valid Loss : 3.020\n",
      "Valid Macro F1  : 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.981\n",
      "Valid Loss : 2.975\n",
      "Valid Macro F1  : 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:24<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.937\n",
      "Valid Loss : 2.944\n",
      "Valid Macro F1  : 0.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.904\n",
      "Valid Loss : 2.923\n",
      "Valid Macro F1  : 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.878\n",
      "Valid Loss : 2.908\n",
      "Valid Macro F1  : 0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:25<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.857\n",
      "Valid Loss : 2.897\n",
      "Valid Macro F1  : 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.840\n",
      "Valid Loss : 2.890\n",
      "Valid Macro F1  : 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.825\n",
      "Valid Loss : 2.884\n",
      "Valid Macro F1  : 0.063\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "text_classifier = CNN()\n",
    "#text_classifier = LSTM()\n",
    "optimizer = Adam(text_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(text_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1-LZItcweEJ"
   },
   "source": [
    "Как видим, CNN оказалась хуже LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9cURRZH0bSg"
   },
   "source": [
    "Мы также пробовали использовать one-hot эмбеддинги текстов для обучения (код для их получения приведен ниже), но качество  было лишь незначительно ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BQOsB0QlYzD"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def build_vocab(datasets):\n",
    "    for dataset in datasets:\n",
    "        for text, label in dataset:\n",
    "            yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(build_vocab([train_dataset, test_dataset]), specials=[\"<UNK>\"])\n",
    "vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab.get_itos(), tokenizer=tokenizer)\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    X, Y = list(zip(*batch))\n",
    "    X = vectorizer.transform(X).todense()\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(Y) #- 1 ## We have deducted 1 from target names to get them in range [0,1,2,3] from [1,2,3,4]\n",
    "\n",
    "#train_dataset, test_dataset  = torchtext.datasets.AG_NEWS()\n",
    "#train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, collate_fn=vectorize_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=256, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8PEzUGfALEw"
   },
   "source": [
    "## 3. Аугментации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qevwb0x5DenL"
   },
   "source": [
    "Дополним обучающее множество сэмплами, в каждом из которых 4 случайных слова заменены синонимами. Получим эти сэмплы, аугментировав первые 10000 наблюдений из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4_lbhoYAD3n",
    "outputId": "9eb19c7e-bfdd-4d81-b89c-d214ea1c01be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting nlpaug\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "\u001b[K     |████████████████████████████████| 410 kB 5.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (1.21.6)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (2.23.0)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (3.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
      "Installing collected packages: nlpaug\n",
      "Successfully installed nlpaug-1.1.11\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "0AdqOq7gCQbD"
   },
   "outputs": [],
   "source": [
    "train_sample = df.loc[:, [1, 2]]\n",
    "test_sample = df_test.loc[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "3BKRTik1Iafe"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(np.array(train_sample.loc[:, 1]).reshape(-1, 1))\n",
    "train_sample[1] = enc.transform(np.array(train_sample.loc[:, 1]).reshape(-1, 1))\n",
    "test_sample[1] = enc.transform(np.array(test_sample.loc[:, 1]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhPMDMkvdB4N",
    "outputId": "c743c8e5-dd00-41c9-fe80-4a4ac7fc60b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#Augmentations \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "#Synonym Replacement\n",
    "aug = naw.SynonymAug(aug_src='wordnet',aug_max=4)\n",
    "aug_train = train_sample.loc[:10000, :]\n",
    "aug_train.loc[:10000, 2] = train_sample.loc[:10000, 2].apply(lambda x: aug.augment(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "_gfpc2p4-s62"
   },
   "outputs": [],
   "source": [
    "train_sample = pd.concat([train_sample, aug_train]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "SIzWzpNU_8Dd"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    " \n",
    "  def __init__(self, train = True):\n",
    "    if train:\n",
    "      x=train_sample[2].values\n",
    "      y=train_sample[1].values\n",
    "    else:\n",
    "      x=test_sample[2].values\n",
    "      y=test_sample[1].values\n",
    " \n",
    "    self.x_train=x\n",
    "    self.y_train=torch.tensor(y).type(torch.LongTensor)\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.y_train)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_train[idx],self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "2F9IykEn_sr3"
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = MyDataset(), MyDataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "LJJe_Jk_JYzo"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "vectorizer = Text2VecTransformer()\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    X, Y = list(zip(*batch))\n",
    "    X_vect = np.array([vectorizer.transform(x) for x in X])\n",
    "    return torch.tensor(X_vect, dtype=torch.float32), torch.tensor(Y)\n",
    "\n",
    "#train_dataset, test_dataset  = torchtext.datasets.AG_NEWS()\n",
    "#train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, collate_fn=vectorize_batch)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=256, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz39kc8hlPvL"
   },
   "source": [
    "Протестируем на лучшей нейросети LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kCc23o0_-ah",
    "outputId": "5913b49e-5d6d-42de-efef-6f6ea930a38e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.154\n",
      "Valid Loss : 2.914\n",
      "Valid Macro F1  : 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:24<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.851\n",
      "Valid Loss : 2.805\n",
      "Valid Macro F1  : 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.764\n",
      "Valid Loss : 2.763\n",
      "Valid Macro F1  : 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:22<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.712\n",
      "Valid Loss : 2.741\n",
      "Valid Macro F1  : 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:22<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.671\n",
      "Valid Loss : 2.729\n",
      "Valid Macro F1  : 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:22<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.635\n",
      "Valid Loss : 2.724\n",
      "Valid Macro F1  : 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.604\n",
      "Valid Loss : 2.719\n",
      "Valid Macro F1  : 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.572\n",
      "Valid Loss : 2.716\n",
      "Valid Macro F1  : 0.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:22<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.542\n",
      "Valid Loss : 2.723\n",
      "Valid Macro F1  : 0.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:22<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.512\n",
      "Valid Loss : 2.726\n",
      "Valid Macro F1  : 0.089\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#text_classifier = MLP()\n",
    "text_classifier = LSTM()\n",
    "optimizer = Adam(text_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(text_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbhHBgNkyNbG"
   },
   "source": [
    "Простестируем CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpmuNUHGCDbJ",
    "outputId": "ca42080f-fc54-469c-dc13-e7910aabcb10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:26<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.408\n",
      "Valid Loss : 3.192\n",
      "Valid Macro F1  : 0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.105\n",
      "Valid Loss : 3.073\n",
      "Valid Macro F1  : 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:25<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 3.022\n",
      "Valid Loss : 3.020\n",
      "Valid Macro F1  : 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.974\n",
      "Valid Loss : 2.987\n",
      "Valid Macro F1  : 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:26<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.938\n",
      "Valid Loss : 2.962\n",
      "Valid Macro F1  : 0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.909\n",
      "Valid Loss : 2.943\n",
      "Valid Macro F1  : 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:25<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.884\n",
      "Valid Loss : 2.928\n",
      "Valid Macro F1  : 0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.862\n",
      "Valid Loss : 2.916\n",
      "Valid Macro F1  : 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.844\n",
      "Valid Loss : 2.907\n",
      "Valid Macro F1  : 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:25<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 2.828\n",
      "Valid Loss : 2.899\n",
      "Valid Macro F1  : 0.060\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "text_classifier = CNN()\n",
    "#text_classifier = LSTM()\n",
    "optimizer = Adam(text_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(text_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXUmzPD3bVg7"
   },
   "source": [
    "# Часть 4. Итоги\n",
    "Подведем итоги:\n",
    "* Пункт 1. Данный пункт представлял собой проведение эксплоративного анализа, в частности, здесь нами был произведен поиск наиболее часто употребляемых слов (п. 1.1.), а также имен, пар имя + фамилия, пар вида \"профессор\" + имя / фамилия (п 1.2.)\n",
    "  * Пункт 1.1. Касательно результатов этого пункта можно сказать, что в целом картина по топ-словам является более-менее ожидаемой (с учетом тематики текстов, что отражается в основном в присутствии в топе имен главных персонажей). Немного неожиданным оказалось лишь то, что отрицательная частица \"not\" в сокращенной форме (\"nt\") является настолько часто употребляемой.\n",
    "  * Пункт 1.2. Для поиска имен был использован внешний источник с данными о подавляющем большинстве персонажей вселенной Гарри Поттера. Процесс извлечения имен может быть распараллелен, так как чтение и проверка вхождения не зависят в текстах друг от друга. Для разделения на имя и фамилию отдельную сложность представляли ФИО с длиной более двух, например Thomas Marvolo Riddle или даже более длинные. Кроме того, отдельной обработки требовали такие имена, как Grey Lady, которые состоят двух слов, но при простом сплите по пробелу разделились бы на имя и фамилию неверно и могли значительно исказить итоговую статистику по частотности. Для решения упомянутых сложностей предобработка списка имен производилась в ручном режиме. В конечном итоге, по всем трем подпунктам получились ожидаемые результаты - это центральные персонажи.\n",
    "* Пункт 2. В данном пункте на предоставленном корпусе нами была обучена модель word2vec. Проанализировав результаты поиска синонимов, ассоциаций и лишних слов с использованием обученной модели, а также визуализацию на плоскости t-SNE представлений слов из п. 1.1, мы заключили, что полученная модель является адекватной.  \n",
    "Небольшая техническая ремарка про трейд-офф между оперативной памятью и скоростью работы. Использование генераторов и чтение одного документа за раз позволяет снизить нагрузку на оперативную память, но при этом скорость обучения word2vec низкая, так как нет параллельности. Для использования многопоточности необходима предобработка данных, заключающаяся в записи единого обучающего корпуса, где каждый документ располагается на новой строке. Такой подход позволяет использовать многопоточность в процессе обучения, но тогда при формирования корпуса мы работаем в один поток. \n",
    "* Пункт 3.\n",
    "  * Пункт 3.1. В качестве бенчмарк классификатора был использова Fasttext. Качество классификации (F1 score на тесте) составило около 0.2.\n",
    "  * Пункт 3.2. Нами была обучены CNN и LSTM сети для классификации текстов. LSTM показала себя лучше CNN. Мы обучали сети на полученных в предыдущих пунктах word2vec эмбеддингах. F1 score на тесте для LSTM после 10 эпох составило около 0.09, что, хотя и ниже нашего бейзлайна из пункта 3.1, вполне соответсвует результатам полученным для подобной модели в базовой статье (см. табл. 3): https://arxiv.org/pdf/1905.11037.pdf\n",
    "  * Пункт 3.3. Добавление аугментированных сэмплов не улучшило качества модели. Возможно, стоит попробовать другие типа аугментации (напр., удаление случайного слова) или увеличить количество аугментированных сэмплов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwu40onndzBd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jnnoTWoBJk8x",
    "Kz8yh0ccgmrY",
    "rXUmzPD3bVg7"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
